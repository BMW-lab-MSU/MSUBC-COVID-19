# -*- coding: utf-8 -*-
"""Feed_Forwards_Model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qrcli181qIwI5pOpUHyC_PAFRoe4_7Ut
"""

# Commented out IPython magic to ensure Python compatibility.


from __future__ import absolute_import, division, print_function
import tensorflow as tf


import pandas as pd
import numpy as np
from datetime import datetime
from datetime import timedelta

#!pip install tensorflow==2.0
from tensorflow import keras
from tensorflow.keras import layers

#!pip install keras

from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn import linear_model
from sklearn import ensemble
from sklearn import tree
from sklearn import svm
from sklearn import neighbors

#from xgboost import XGBRegressor
#from xgboost import XGBRFRegressor

import seaborn as sns; sns.set()
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
# %matplotlib inline

from IPython.core.display import display, HTML
display(HTML("<style>.container { width:92% !important; }</style>"))

import pickle

  # Import updated data and format into ML format
from datetime import date

d0 = date(2021, 2, 28)
d1 = date.today()

gap = abs(d0-d1)
gap = gap.days

average_mae_test1 = []
average_mae_test2 = []
average_mae_test3 = []
average_mae_test4 = []
average_mae_test5 = []
average_mae_test6 = []
average_mae_test7 = []
average_mse_test1 = []
average_mse_test2 = []
average_mse_test3 = []
average_mse_test4 = []
average_mse_test5 = []
average_mse_test6 = []
average_mse_test7 = []
average_r2_test1 = []
average_r2_test2 = []
average_r2_test3 = []
average_r2_test4 = []
average_r2_test5 = []
average_r2_test6 = []
average_r2_test7 = []



csse_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv')
wy_df = csse_df[csse_df['Province_State'] == 'Wyoming']
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
nd_df = csse_df[csse_df['Province_State'] == 'North Dakota']
mt_df = csse_df[csse_df['Province_State'] == 'Montana']
sd_df = csse_df[csse_df['Province_State'] == 'South Dakota']
id_df = csse_df[csse_df['Province_State'] == 'Idaho']
df = pd.concat([wy_df,nd_df,mt_df,sd_df,id_df], ignore_index=True)
df['Location'] = df['Admin2'].str.cat(df['Province_State'], sep=', ')
df = df.drop(columns=['UID','code3','iso2','iso3','FIPS','Country_Region','Lat','Long_','Combined_Key',
                      #'2/1/20','2/2/20','2/3/20','2/4/20','2/5/20',
                      #'2/6/20','2/7/20','2/8/20','2/9/20','2/10/20','2/11/20','2/12/20','2/13/20','2/14/20','2/15/20','2/16/20','2/17/20','2/18/20',
                      #'2/19/20','2/20/20','2/21/20','2/22/20','2/23/20','2/24/20','2/25/20','2/26/20','2/27/20','2/28/20','2/29/20','3/1/20','3/2/20',
                      #'3/3/20','3/4/20','3/5/20','3/6/20','3/7/20','3/8/20','3/9/20','3/10/20',
                      'Admin2','Province_State'])

headers_vals = list(df['Location'])
headers_vals.insert(0,'Date')
df = df.drop(columns=['Location'])
df = df.transpose().reset_index()
df.columns = headers_vals
df = df.set_index('Date')
df = df.drop(columns=['Out of WY, Wyoming','Unassigned, Wyoming','Out of ND, North Dakota','Unassigned, North Dakota','Out of MT, Montana',
                      'Unassigned, Montana','Out of SD, South Dakota','Unassigned, South Dakota','Out of ID, Idaho','Unassigned, Idaho'])

# Extra county data
csse_df_extra = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv')
wa_df = csse_df[csse_df['Province_State'] == 'Washington']
or_df = csse_df[csse_df['Province_State'] == 'Oregon']
nv_df = csse_df[csse_df['Province_State'] == 'Nevada']
ut_df = csse_df[csse_df['Province_State'] == 'Utah']
co_df = csse_df[csse_df['Province_State'] == 'Colorado']
ne_df = csse_df[csse_df['Province_State'] == 'Nebraska']
ia_df = csse_df[csse_df['Province_State'] == 'Iowa']
mn_df = csse_df[csse_df['Province_State'] == 'Minnesota']
df_extra = pd.concat([wa_df,or_df,nv_df,ut_df,co_df,ne_df,ia_df,mn_df,], ignore_index=True)
df_extra['Location'] = df_extra['Admin2'].str.cat(df_extra['Province_State'], sep=', ')
df_extra = df_extra.drop(columns=['UID','code3','iso2','iso3','FIPS','Country_Region','Lat','Long_','Combined_Key','Admin2','Province_State'])
headers_vals = list(df_extra['Location'])
headers_vals.insert(0,'Date')
df_extra = df_extra.drop(columns=['Location'])
df_extra = df_extra.transpose().reset_index()
df_extra.columns = headers_vals
df_extra = df_extra.set_index('Date')

df_new_cases_only_extra = pd.DataFrame()
for i in list(df_extra):
    df_new_cases_only_extra[i] = [second - first for first, second in zip(df_extra[i], df_extra[i][1:])]
df_extra = df_new_cases_only_extra

# Convert to new cases only
df_new_cases_only = pd.DataFrame()
for i in list(df):
  array = [second - first for first, second in zip(df[i], df[i][1:])]
  # Make all negative values 0
  pos_array = []
  for j in array:
      if j < 0:
          a = 0
      else:
          a = j
      pos_array.append(a)
  df_new_cases_only[i] = pos_array
    
# Convert all to floats

df_new_cases_only = df_new_cases_only.astype(float)
df = df_new_cases_only
p = 0
for i in df:
  df[i] = df.iloc[:,p].rolling(window=7).mean()
  p = p + 1
df = df[7:len(df)].reset_index(drop=True)
# New way to generate arrays of length X
interval = 40
features = []
labels = []
counties = []
actual = []
day = []

days = 3
# Iterate across dataframe, one county at a time
for county in list(df):
  seq = list(df[county])

  day0 = seq[0:len(seq)-gap-days]
  day1 = seq[0+days:len(seq)-gap]

  actual.append(day0)
  day.append(day1)


mse_test = mean_squared_error(actual, day)
mae_test = mean_absolute_error(actual, day)
r_2 = r2_score(actual, day)

print(mse_test)
print(mae_test)
print(r_2)